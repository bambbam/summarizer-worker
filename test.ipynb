{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 01:47:16.252578: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-24 01:47:16.252750: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8490731716156006\n"
     ]
    }
   ],
   "source": [
    "from summarizer.domain.model.video import Video\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = Video(url=\"tests/2.mp4\")\n",
    "images = video._read_video()\n",
    "idx, image = next(images)\n",
    "matplotlib.pyplot.imshow(image.frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = image.extract()\n",
    "print(features)\n",
    "video.shorten(video_feature=features, must_include_feature=[\"person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 4625\n",
      "width : 640\n",
      "height : 360\n",
      "fps : 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 01:47:22.701826: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "video = Video(url=\"tests/2.mp4\") \n",
    "list_of_feature = video.extract_feature()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 0\n",
      "width : 0\n",
      "height : 0\n",
      "fps : 0.0\n"
     ]
    }
   ],
   "source": [
    "video.shorten(video_feature=list_of_feature, must_include_feature=[\"person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video2 = Video(url=\"tests/2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video2._read_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 4625\n",
      "width : 640\n",
      "height : 360\n",
      "fps : 25.0\n"
     ]
    }
   ],
   "source": [
    "video2.shorten(video_feature=list_of_feature, must_include_feature=[\"person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "video_feature = list_of_feature\n",
    "must_include_feature = [\"person\"]\n",
    "parameter = video2._get_parameter()\n",
    "images = video2._read_video()\n",
    "fps = parameter[\"fps\"]\n",
    "one_sec_images = []\n",
    "to_concat_timeframe = []\n",
    "concated_image = []\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter(\"out.mp4\", fourcc, fps, (parameter[\"width\"], parameter[\"height\"]))\n",
    "\n",
    "for feature in video_feature:\n",
    "    ch = False\n",
    "    for x in must_include_feature:\n",
    "        if x == feature.name:\n",
    "            ch = True\n",
    "            break\n",
    "    if ch:\n",
    "        to_concat_timeframe.append(feature.current_frame)\n",
    "\n",
    "print(to_concat_timeframe)\n",
    "for idx, image in images:\n",
    "    one_sec_images.append(image)\n",
    "    if(idx%fps == 0):\n",
    "        if(idx in to_concat_timeframe):\n",
    "            concated_image.extend(one_sec_images)\n",
    "        one_sec_images = []\n",
    "print(len(concated_image))\n",
    "for image in concated_image:\n",
    "    out.write(image.frame)\n",
    "out.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19c3d63fb0fca6ad034ff5f3341e7200cfedea1264701a9bb919ca3873d1b28a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('summarizer-server-05flj79H-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
