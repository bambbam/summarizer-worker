video를 한 프레임씩 읽으면 -> image(frame번호, image클래스) 리턴
image 클래스에 frame번호와 Detector가 있음, Detector는 어떤 알고리즘(욜로/타이니욜로)을 사용해서 feature extract를 해줌 
extract함수를 보면 detections변수가 있음
detections[0]는 RGB 이미지
detections[1]에 (x,3) list {name, box, 확률값}

단계:
*  1. Video 클래스 하나 선언(변수들 초기화)
   * ```video = Video(key="123",url="tests/2.mp4", algorithm="yolov3") ```
*  2. _read_video()하면 한프레임씩 이미지를 읽고 (frame_id, image 클랙스)를 리턴함
   *  ```images = video._read_video()```
*  3. image.extract()는 Detector.extract()와 같다. 한 프레임에서 나타난 이미지들의 feature를 추출함 
   *  ```features = image.extract()```
   4. 클러스터링을 하려면 일단 모든 이미지들을 읽어야함
      * next, yield를 꼭 사용해야 하나

face_recognition input : image 클래스 , output: FrameFeature 
 * 5. 클러스터링 input: recognition에서 얻은 128차 feature값들 / FrameFeature의 리스트
 * ouput : cm.labels_
 * 

